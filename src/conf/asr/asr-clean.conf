[train]
seed: 72000
model_type: ASR
patience: 20
max_epochs: 100
eval_freq: 1000
eval_metrics: wer,loss
# this is a bpe model so de-bpe is necessary for correct WER computation
eval_filters: de-bpe
eval_beam: 5
eval_batch_size: 16
save_best_metrics: True
eval_max_len: 400
n_checkpoints: 0
l2_reg: 0
gclip: 1
optimizer: adam
lr: 0.0004
lr_decay: plateau
lr_decay_revert: False
lr_decay_factor: 0.5
lr_decay_patience: 2
batch_size: 36
save_path: ../exp/asr-clean
pretrained_file: ${data:data_path}/models/speechcoco_pretrain_ckpts/asr.ckpt 
tensorboard_dir: ${save_path}/tb

[model]
att_type: mlp
att_bottleneck: hid
feat_dim: 43
enc_dim: 256
proj_dim: 256
emb_dim: 256
dec_dim: 256
dropout: 0.4
# 6 encoder layers
enc_layers: '1_1_2_2_1_1'
tied_dec_embs: True
dec_init: mean_ctx
bucket_by: en_speech
# Enough coverage @ 1500
max_len: 1500

direction: en_speech:Kaldi -> en_text:Text

[data]
data_path: /project/ocean/tsriniva/data_MultimodalASR
root: ${data_path}/fbank_feats/data
text_root: ${data_path}/text_files

train_set: {'en_speech': '${root}/train_clean',
            'en_text': '${text_root}/train.en'}

val_set: {'en_speech': '${root}/dev_clean',
          'en_text': '${text_root}/dev.en'}

test_set: {'en_speech': '${root}/test_clean',
           'en_text': '${text_root}/test.en'}


[vocabulary]
en_text: ${data:text_root}/flickr8k-min10.vocab

